# src/energydoc_talk_ai/ingestion/vector_store.py

"""
Module de cr√©ation et r√©cup√©ration du VectorStore Pinecone.

Ce module :
- Initialise un client Pinecone
- Cr√©e l‚Äôindex si n√©cessaire
- Attache un mod√®le d‚Äôembedding (Google / OpenAI / autre)
- Retourne un VectorStore compatible LangChain

Utilis√© dans le pipeline RAG :
    documents ‚Üí embeddings ‚Üí PineconeVectorStore
"""

import time
from typing import List
from langchain.schema import Document
from pinecone import Pinecone, ServerlessSpec
from langchain_pinecone import PineconeVectorStore
from energydoc_talk_ai.core.config import settings
from energydoc_talk_ai.core.logger import setup_logger
from energydoc_talk_ai.ingestion.embeddings import get_embeddings



# ------------------------------------------------------------------------------
# Suppression de l‚Äôindex Pinecone (utilitaire)
# ------------------------------------------------------------------------------
def delete_pinecone_index() -> None:
    """
    Supprime un index Pinecone uniquement s'il existe.
    Ne l√®ve PAS d'erreur si l'index n'existe pas.
    """

    # Initialisation du logger
    logger = setup_logger(logger_name="delete_pinecone_index")


    logger.info(f"V√©rification pour suppression de l‚Äôindex : {settings.PINECONE_INDEX_NAME}")

    pc = Pinecone(api_key=settings.PINECONE_API_KEY)

    # Liste des index existants
    existing_indexes = [idx["name"] for idx in pc.list_indexes()]

    # Si l'index n'existe pas ‚Üí rien √† faire
    if settings.PINECONE_INDEX_NAME not in existing_indexes:
        logger.warning(
            f"Index '{settings.PINECONE_INDEX_NAME}' introuvable ‚Üí aucune suppression."
        )
        return

    # Suppression
    logger.info(f"Suppression de l‚Äôindex '{settings.PINECONE_INDEX_NAME}'...")
    pc.delete_index(settings.PINECONE_INDEX_NAME)
    logger.info(f"Index '{settings.PINECONE_INDEX_NAME}' supprim√© avec succ√®s.")



# ------------------------------------------------------------------------------
# Initialisation du client Pinecone
# ------------------------------------------------------------------------------
def get_pinecone_client() -> Pinecone:
    """
    Initialise le client Pinecone et cr√©e l'index si n√©cessaire.

    Returns
    -------
    Pinecone
        Client Pinecone configur√© avec API Key + Region.
    """
    # Initialisation du logger
    logger = setup_logger(logger_name="get_pinecone_client")
    
    logger.info("Initialisation du client Pinecone...")

    # Cr√©ation du client Pinecone
    try:
        pc = Pinecone(api_key=settings.PINECONE_API_KEY)
        logger.debug("Client Pinecone initialis√©.")
    except Exception as exc:  # noqa: BLE001
        logger.error(f"Impossible d'initialiser le client Pinecone : {exc}")
        raise

    # Configuration serverless (AWS)
    spec = ServerlessSpec(
        cloud="aws",
        region=settings.PINECONE_SERVERLESS_REGION,
    )

    # Liste des index existants
    try:
        existing_indexes = [i["name"] for i in pc.list_indexes()]
        logger.info(f"Index existants : {existing_indexes}")
    except Exception as exc:
        logger.error(f"Impossible de lister les index Pinecone : {exc}")
        raise

    # Cr√©ation de l'index si inexistant
    if settings.PINECONE_INDEX_NAME not in existing_indexes:
        logger.warning(
            f"Index '{settings.PINECONE_INDEX_NAME}' introuvable ‚Üí cr√©ation..."
        )

        try:
            pc.create_index(
                name=settings.PINECONE_INDEX_NAME,
                dimension=settings.PINECONE_DIMENSION,  # Google embeddings en fonction du mod√®le d'embedding utilis√©
                metric=settings.PINECONE_METRIC,
                spec=spec,
            )
        except Exception as exc:
            logger.error(f"Erreur cr√©ation index Pinecone : {exc}")
            raise

        # Attendre que l‚Äôindex soit pr√™t
        logger.info("Cr√©ation de l‚Äôindex en cours...")

        while True:
            try:
                status = pc.describe_index(settings.PINECONE_INDEX_NAME).status
                logger.debug(f"Statut index : {status}")
            except Exception as exc:
                logger.error(f"Impossible de r√©cup√©rer le statut : {exc}")
                raise

            if status.get("ready", False):
                logger.info("Index pr√™t ! üöÄ")
                break

            time.sleep(1)
            logger.debug("Attente disponibilit√© index...")

    else:
        logger.info(
            f"Index '{settings.PINECONE_INDEX_NAME}' d√©j√† existant ‚Üí utilisation."
        )

    return pc


# ----------------------------------------------------------------------
# Ajout : Insertion batch√©e pour √©viter la limite Google
# ----------------------------------------------------------------------
def add_documents_batch_safe(
    vector_store: PineconeVectorStore,
    documents: List[Document],
    batch_size: int = 32,
) -> None:
    """
    Ajout s√©curis√© de documents dans Pinecone en batchs,
    pour √©viter les limites d'embeddings Google GenAI.

    Parameters
    ----------
    vector_store : PineconeVectorStore
        Le VectorStore LangChain cible.
    documents : List[Document]
        Les chunks √† indexer.
    batch_size : int
        Taille du batch √† embeder (+ recomm: 16 ou 32 avec Google).
    """
    # Initialisation du logger
    logger = setup_logger(logger_name="add_documents_batch_safe")

    logger.info(
        f"Indexation batch√©e avec batch_size={batch_size} "
        f"({len(documents)} documents au total)."
    )

    for i in range(0, len(documents), batch_size):
        batch = documents[i : i + batch_size]
        logger.info(f" ‚Üí Batch {i//batch_size + 1}: {len(batch)} documents")

        # Embeddings + insertion
        vector_store.add_documents(batch)

        logger.debug("Batch index√© avec succ√®s.")

    logger.info("Indexation batch√©e termin√©e.")


# ------------------------------------------------------------------------------
# R√©cup√©ration du VectorStore LangChain
# ------------------------------------------------------------------------------
def get_vector_store() -> PineconeVectorStore:
    """
    Retourne un VectorStore LangChain bas√© sur l'index Pinecone existant.

    Returns
    -------
    PineconeVectorStore
        Le VectorStore configur√© avec l'embedding choisi.
    """
    # Initialisation du logger
    logger = setup_logger(logger_name="get_vector_store")
    
    logger.info("Initialisation du VectorStore Pinecone...")

    pc = get_pinecone_client()

    # R√©cup√©rer l‚Äôindex Pinecone
    try:
        index = pc.Index(settings.PINECONE_INDEX_NAME)
        logger.debug(f"Index r√©cup√©r√© : {settings.PINECONE_INDEX_NAME}")
    except Exception as exc:
        logger.error(f"Impossible de r√©cup√©rer l‚Äôindex : {exc}")
        raise

    # Embeddings (Google / OpenAI / HuggingFace)
    try:
        embeddings = get_embeddings()
        logger.debug("Embedding model charg√©.")
    except Exception as exc:
        logger.error(f"Impossible de charger les embeddings : {exc}")
        raise

    # Cr√©ation du VectorStore LangChain
    try:
        vector_store = PineconeVectorStore(
            index=index,
            embedding=embeddings,
            text_key="text",  # cl√© utilis√©e dans les documents stock√©s
        )
        logger.info("VectorStore Pinecone initialis√© avec succ√®s.")
    except Exception as exc:
        logger.error(f"Impossible d'initialiser le VectorStore : {exc}")
        raise

    return vector_store
